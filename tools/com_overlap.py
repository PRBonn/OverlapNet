#!/usr/bin/env python3
# Developed by Xieyuanli Chen and Thomas LÃ¤be
# This file is covered by the LICENSE file in the root of this project.
# Brief: This script generate the overlap and orientation combined mapping file.

from utils.utils import *



def com_overlap_yaw(scan_paths, poses, frame_idx, leg_output_width=360):
    """compute the overlap and yaw ground truth from the ground truth poses,
       which is used for OverlapNet training and testing.
       Args:
         scan_paths: paths of all raw LiDAR scans
         poses: ground-truth poses either given by the dataset or generated by SLAM or odometry
         frame_idx: the current frame index
       Returns:
         ground_truth_mapping: the ground truth overlap and yaw used for training OverlapNet,
                               where each row contains [current_frame_idx, reference_frame_idx, overlap, yaw]
    """
    # init ground truth overlap and yaw
    print('Start to compute ground truth overlap and yaw ...')
    overlaps = []
    # yaw_idxs = []
    # yaw_resolution = leg_output_width

    # we calculate the ground truth for one given frame only
    # generate range projection for the given frame
    current_points = load_vertex(scan_paths[frame_idx])
    current_range, project_points, _, _ = range_projection(current_points)
    visible_points = project_points[current_range > 0]
    valid_num = len(visible_points)
    current_pose = poses[frame_idx]

    for reference_idx in range(len(scan_paths)):
        # generate range projection for the reference frame
        reference_pose = poses[reference_idx]
        reference_points = load_vertex(scan_paths[reference_idx])
        reference_points_world = reference_pose.dot(reference_points.T).T
        reference_points_in_current = np.linalg.inv(current_pose).dot(reference_points_world.T).T
        reference_range, _, _, _ = range_projection(reference_points_in_current)

        # calculate overlap
        overlap = np.count_nonzero(
            abs(reference_range[reference_range > 0] - current_range[reference_range > 0]) < 1) / valid_num
        overlaps.append(overlap)

        # calculate yaw angle
        relative_transform = np.linalg.inv(current_pose).dot(reference_pose)
        relative_rotation = relative_transform[:3, :3]
        # _, _, yaw = euler_angles_from_rotation_matrix(relative_rotation)

        # discretize yaw angle and shift the 0 degree to the center to make the network easy to lean
        # yaw_element_idx = int(- (yaw / np.pi) * yaw_resolution // 2 + yaw_resolution // 2)
        # yaw_idxs.append(yaw_element_idx)

        # print('finished pair id: ', reference_idx)

    # ground truth format: each row contains [current_frame_idx, reference_frame_idx, overlap, yaw]
    ground_truth_mapping = np.zeros((len(scan_paths), 4))
    ground_truth_mapping[:, 0] = np.ones(len(scan_paths)) * frame_idx
    ground_truth_mapping[:, 1] = np.arange(len(scan_paths))
    ground_truth_mapping[:, 2] = overlaps
    # ground_truth_mapping[:, 3] = yaw_idxs

    print('Finish generating ground_truth_mapping!')

    return ground_truth_mapping


if __name__ == '__main__':
    scan_folder = "/home/mjy/datasets/kitti/07/velodyne/sequences/07/velodyne"
    scan_paths = load_files(scan_folder)
    calib_file = "/home/mjy/repo/OverlapNet_for_TF2/data/07/calib.txt"
    poses_file = "/home/mjy/repo/OverlapNet_for_TF2/data/07/poses.txt"
    # load calibrations
    T_cam_velo = load_calib(calib_file)
    T_cam_velo = np.asarray(T_cam_velo).reshape((4, 4))
    T_velo_cam = np.linalg.inv(T_cam_velo)
    # load poses
    poses = load_poses(poses_file)
    pose0_inv = np.linalg.inv(poses[0])

    # for KITTI dataset, we need to convert the provided poses
    # from the camera coordinate system into the LiDAR coordinate system
    poses_new = []
    for pose in poses:
        poses_new.append(T_velo_cam.dot(pose0_inv).dot(pose).dot(T_cam_velo))
    poses = np.array(poses_new)

    # for i in range(1101):
    #     ground_truth_mapping = com_overlap_yaw(scan_paths, poses, frame_idx=i, leg_output_width=360)
    # print(scan_paths)
    ground_truth_mapping = com_overlap_yaw(scan_paths, poses, frame_idx=0, leg_output_width=360)
    print(ground_truth_mapping[:,2])
